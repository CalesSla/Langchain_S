{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-87Jecbh3VVS6qZEMJ8DWDtW0nYM4h at 0x2b07faad6d0> JSON: {\n",
       "  \"id\": \"chatcmpl-87Jecbh3VVS6qZEMJ8DWDtW0nYM4h\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1696754538,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"Hello! I am a helpful virtual assistant. I can assist you with a wide range of tasks and provide information on various topics. How can I assist you today?\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 26,\n",
       "    \"completion_tokens\": 33,\n",
       "    \"total_tokens\": 59\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "response = openai.ChatCompletion.create(model = 'gpt-3.5-turbo',\n",
    "                                        messages = [{'role': 'system', 'content': \"You are a helpful assistant.\"},\n",
    "                                                    {'role': 'user', 'content': 'Hello, what kind of assistant are you?'}])\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! I am a helpful virtual assistant. I can assist you with a wide range of tasks and provide information on various topics. How can I assist you today?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT: Hello! I am an AI-powered assistant named Kate. I can help answer questions, provide information, and assist with various tasks. How can I assist you today? \n",
      " 75 tokens used\n",
      "ChatGPT: Hello! I am an AI-powered assistant named Kate. I can help answer questions, provide information, and assist with various tasks. How can I assist you today? \n",
      " 75 tokens used\n",
      "ChatGPT: Hello! I am an AI-powered assistant named Kate. I can help answer questions, provide information, and assist with various tasks. How can I assist you today? \n",
      " 75 tokens used\n",
      "ChatGPT: Hello! I am an AI-powered assistant named Kate. I can help answer questions, provide information, and assist with various tasks. How can I assist you today? \n",
      " 75 tokens used\n",
      "ChatGPT: Marcus Aurelius served as the Roman Emperor from 161 AD to 180 AD. He was the last of the \"Five Good Emperors\" of Rome. \n",
      " 237 tokens used\n",
      "ChatGPT: Marcus Aurelius served as the Roman Emperor from 161 AD to 180 AD. He was the last of the \"Five Good Emperors\" of Rome. \n",
      " 237 tokens used\n",
      "ChatGPT: Marcus Aurelius was married to Faustina the Younger. She was the daughter of Antoninus Pius, who was the Roman Emperor before Marcus Aurelius. \n",
      " 320 tokens used\n",
      "1094 tokens used in this conversation\n"
     ]
    }
   ],
   "source": [
    "messages = [{'role': 'system', 'content': \"You are a helpful assistant named Kate.\"},\n",
    "            {'role': 'user', 'content': 'Hello, what kind of assistant are you?'}]\n",
    "\n",
    "conversation_total_tokens = 0\n",
    "\n",
    "while True:\n",
    "    message = input('Human: ')\n",
    "    if message == 'exit':\n",
    "        print(f'{conversation_total_tokens} tokens used in this conversation')\n",
    "        break\n",
    "    if message:\n",
    "        messages.append({'role': 'user', 'content': message})\n",
    "        response = openai.ChatCompletion.create(model = 'gpt-3.5-turbo', messages = messages)\n",
    "\n",
    "    reply = response.choices[0].message.content\n",
    "    total_tokens = response.usage['total_tokens']\n",
    "    conversation_total_tokens += total_tokens\n",
    "    print(f'ChatGPT: {reply} \\n {total_tokens} tokens used')\n",
    "    messages.append({'role': 'assistant', 'content': reply})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\llms\\openai.py:753: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Marcus Aurelius was the emperor of Rome from 161 to 180 AD. He was a philosopher-king who ruled during a time of great challenges for the Roman Empire. His reign was marked by military conflicts, including wars against Germanic tribes and the Parthian Empire. Despite these challenges, Marcus Aurelius is best known for his philosophical writings, particularly his book \"Meditations,\" which offers insights into his personal reflections on life, virtue, and the pursuit of wisdom. His reign is considered a significant period in Roman history, as he was the last of the \"Five Good Emperors\" and his death marked the end of a relatively stable and prosperous era for the empire.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI, OpenAIChat\n",
    "\n",
    "prefix_messages = [{'role': 'system', 'content': 'You are a helpful history professor named Kate.'}]\n",
    "\n",
    "llm = OpenAIChat(model_name = 'gpt-3.5-turbo', temperature = 0, prefix_messages=prefix_messages, max_tokens = 256)\n",
    "\n",
    "template = \"\"\"Take the following question: {user_input}\n",
    "Answer it in an informative and interesting but conscise way for someone who is new to the topic.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables= ['user_input'])\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm = llm)\n",
    "\n",
    "user_input = 'When was Marcus Aurelius the emperor of Rome?'\n",
    "\n",
    "llm_chain.run(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Marcus Aurelius, the Roman Emperor from 161 to 180 AD, was married to Faustina the Younger. Faustina was not only his wife but also the mother of his thirteen children. She was known for her beauty and intelligence, and she played an influential role in the imperial court. However, it is important to note that while Marcus Aurelius was a devoted husband, his reign was marked by numerous challenges and conflicts, both within the empire and on its borders.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "user_input = \"Who was Marcus Aurelius married to?\"\n",
    "\n",
    "llm_chain.run(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

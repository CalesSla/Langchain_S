{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huggingface models\n",
    "overall_temperature = 0.1\n",
    "\n",
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n",
    "\n",
    "flan_20B = HuggingFaceHub(repo_id = 'google/flan-ul2',\n",
    "                          model_kwargs={'temperature': overall_temperature,\n",
    "                                        'max_new_tokens': 200})\n",
    "\n",
    "flan_t5xxl = HuggingFaceHub(repo_id='google/flan-t5-xxl',\n",
    "                            model_kwargs={'temperature': overall_temperature,\n",
    "                                          'max_new_tokens': 200})\n",
    "\n",
    "gpt_j6B = HuggingFaceHub(repo_id='EleutherAI/gpt-j-6B',\n",
    "                         model_kwargs={'temperature': overall_temperature,\n",
    "                                       'max_new_tokens': 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI models\n",
    "from langchain.llms import OpenAI, OpenAIChat\n",
    "\n",
    "chatGPT_turbo = OpenAIChat(model_name = 'gpt-3.5-turbo',\n",
    "                           temperature = overall_temperature,\n",
    "                           max_tokens = 256)\n",
    "\n",
    "gpt3_davinci_003 = OpenAI(model_name='text-davinci-003',\n",
    "                          temperature=overall_temperature,\n",
    "                          max_tokens = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cohere models\n",
    "# from langchain.llms import Cohere\n",
    "\n",
    "# cohere_command_xl = Cohere(model = 'command-xlarge',\n",
    "#                            temperature=overall_temperature,\n",
    "#                            max_tokens=256)\n",
    "\n",
    "# cohere_command_xl_nightly = Cohere(model='command-xlarge-nightly',\n",
    "#                                    temperature=0.1,\n",
    "#                                    max_tokens=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "What is the oppisite of up?\n",
      "\n",
      "\u001b[1mOpenAIChat\u001b[0m\n",
      "Params: {'model_name': 'gpt-3.5-turbo', 'temperature': 0.1, 'max_tokens': 256}\n",
      "\u001b[36;1m\u001b[1;3mThe opposite of up is down.\u001b[0m\n",
      "\n",
      "\u001b[1mOpenAI\u001b[0m\n",
      "Params: {'model_name': 'text-davinci-003', 'temperature': 0.1, 'max_tokens': 256, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n",
      "\u001b[33;1m\u001b[1;3m The opposite of up is down.\u001b[0m\n",
      "\n",
      "\u001b[1mHuggingFaceHub\u001b[0m\n",
      "Params: {'repo_id': 'google/flan-ul2', 'task': None, 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 200}}\n",
      "\u001b[38;5;200m\u001b[1;3mUp is the opposite of down. Down is below up. Up is on top of down. The answer: down.\u001b[0m\n",
      "\n",
      "\u001b[1mHuggingFaceHub\u001b[0m\n",
      "Params: {'repo_id': 'google/flan-t5-xxl', 'task': None, 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 200}}\n",
      "\u001b[32;1m\u001b[1;3mDown is the opposite of up. Down is the opposite of up. The answer: down.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# comparison lab\n",
    "\n",
    "from langchain.model_laboratory import ModelLaboratory\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['question'])\n",
    "\n",
    "lab = ModelLaboratory.from_llms([chatGPT_turbo,\n",
    "                                 gpt3_davinci_003,\n",
    "                                #  gpt_j6B,\n",
    "                                 flan_20B,\n",
    "                                 flan_t5xxl\n",
    "                                 ]\n",
    "                                 , prompt = prompt)\n",
    "\n",
    "lab.compare('What is the oppisite of up?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "Answer the following question by reasoning step by step. The cafeteria had 23 apples. If they used 20 for lunch, and bought 6 more, how many apples do they have?\n",
      "\n",
      "\u001b[1mOpenAIChat\u001b[0m\n",
      "Params: {'model_name': 'gpt-3.5-turbo', 'temperature': 0.1, 'max_tokens': 256}\n",
      "\u001b[36;1m\u001b[1;3mStep 1: The cafeteria had 23 apples.\n",
      "Step 2: They used 20 apples for lunch.\n",
      "Step 3: To find out how many apples they have left, we subtract the number of apples used from the initial number of apples: 23 - 20 = 3.\n",
      "Step 4: The cafeteria bought 6 more apples.\n",
      "Step 5: To find out how many apples they have now, we add the number of apples they had left after lunch to the number of apples they bought: 3 + 6 = 9.\n",
      "Step 6: Therefore, the cafeteria now has 9 apples.\u001b[0m\n",
      "\n",
      "\u001b[1mOpenAI\u001b[0m\n",
      "Params: {'model_name': 'text-davinci-003', 'temperature': 0.1, 'max_tokens': 256, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n",
      "\u001b[33;1m\u001b[1;3m \n",
      "\n",
      "Step 1: The cafeteria had 23 apples. \n",
      "\n",
      "Step 2: They used 20 for lunch. \n",
      "\n",
      "Step 3: They bought 6 more. \n",
      "\n",
      "Step 4: To find out how many apples they have, we need to add the number of apples they had before (23) to the number of apples they bought (6). \n",
      "\n",
      "Step 5: 23 + 6 = 29 \n",
      "\n",
      "Therefore, the cafeteria has 29 apples.\u001b[0m\n",
      "\n",
      "\u001b[1mHuggingFaceHub\u001b[0m\n",
      "Params: {'repo_id': 'google/flan-t5-xxl', 'task': None, 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 200}}\n",
      "\u001b[38;5;200m\u001b[1;3mThe cafeteria has 23 - 20 = 3 apples left. They bought 6 + 3 = 7 apples. The cafeteria has 7 + 3 = 10 apples. The answer: 10.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lab.compare('Answer the following question by reasoning step by step. The cafeteria had 23 apples. If they used 20 for lunch, and bought 6 more, how many apples do they have?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "\n",
      "Can Geoffrey Hinton have a conversation with George Washington? Give the rationale before answering.\n",
      "\n",
      "\n",
      "\u001b[1mOpenAIChat\u001b[0m\n",
      "Params: {'model_name': 'gpt-3.5-turbo', 'temperature': 0.1, 'max_tokens': 256}\n",
      "\u001b[36;1m\u001b[1;3mFirst, we need to consider the fact that Geoffrey Hinton is a renowned computer scientist and one of the pioneers of deep learning and artificial intelligence. On the other hand, George Washington was the first President of the United States and lived during the 18th century.\n",
      "\n",
      "Given this information, it is clear that Geoffrey Hinton and George Washington belong to different time periods. Hinton is a contemporary figure, while Washington lived over two centuries ago. Therefore, it is impossible for them to have a direct conversation in the traditional sense.\n",
      "\n",
      "However, if we consider the hypothetical scenario of time travel or some advanced technology that allows communication across time periods, it might be possible for Hinton and Washington to exchange information or have a conversation. But this would require significant advancements in science and technology that currently do not exist.\n",
      "\n",
      "In conclusion, based on the current understanding of time and technology, Geoffrey Hinton cannot have a conversation with George Washington.\u001b[0m\n",
      "\n",
      "\u001b[1mOpenAI\u001b[0m\n",
      "Params: {'model_name': 'text-davinci-003', 'temperature': 0.1, 'max_tokens': 256, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n",
      "\u001b[33;1m\u001b[1;3m First, Geoffrey Hinton is a living person, while George Washington is a deceased person. Second, a conversation requires two living people to communicate with each other. Therefore, no, Geoffrey Hinton cannot have a conversation with George Washington.\u001b[0m\n",
      "\n",
      "\u001b[1mHuggingFaceHub\u001b[0m\n",
      "Params: {'repo_id': 'google/flan-ul2', 'task': None, 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 200}}\n",
      "\u001b[38;5;200m\u001b[1;3mGeorge Washington died in 1799. Geoffrey Hinton was born in 1959. So, the final answer is no.\u001b[0m\n",
      "\n",
      "\u001b[1mHuggingFaceHub\u001b[0m\n",
      "Params: {'repo_id': 'google/flan-t5-xxl', 'task': None, 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 200}}\n",
      "\u001b[32;1m\u001b[1;3mGeorge Washington died in 1799. Geoffrey Hinton was born in 1939. The answer: no.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lab.compare(\"\"\"\n",
    "Can Geoffrey Hinton have a conversation with George Washington? Give the rationale before answering.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "\n",
      "Write a sad story about a carrot named Jason. The story should start with the carrot being a professional athlete of some kind, and end with the carrot having his heart broken.\n",
      "\n",
      "\n",
      "\u001b[1mOpenAIChat\u001b[0m\n",
      "Params: {'model_name': 'gpt-3.5-turbo', 'temperature': 0.1, 'max_tokens': 256}\n",
      "\u001b[36;1m\u001b[1;3mOnce upon a time, in the vibrant land of Veggieville, there lived a carrot named Jason. Jason was not your ordinary carrot; he possessed an extraordinary talent for running. With his slender body and vibrant orange hue, he had become a professional athlete, competing in the prestigious Veggie Games.\n",
      "\n",
      "Jason had always dreamt of becoming a champion, and his hard work and dedication had finally paid off. He had won numerous races, breaking records and capturing the hearts of the vegetable community. His speed was unmatched, and he was adored by fans far and wide.\n",
      "\n",
      "One sunny day, as Jason was preparing for his next race, he noticed a beautiful tomato named Lily in the crowd. Her radiant red skin and sparkling green eyes instantly captivated him. From that moment on, Jason's heart belonged to Lily.\n",
      "\n",
      "As the races continued, Jason's love for Lily grew stronger. He would often catch glimpses of her in the stands, cheering him on with her infectious smile. Her presence fueled his determination, and he ran faster than ever before, breaking his own records time and time again.\n",
      "\n",
      "One fateful day, during the final race of the Veggie Games, Jason was on the verge of victory. The crowd erupted in cheers as he sprinted towards the finish line,\u001b[0m\n",
      "\n",
      "\u001b[1mOpenAI\u001b[0m\n",
      "Params: {'model_name': 'text-davinci-003', 'temperature': 0.1, 'max_tokens': 256, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "Jason the carrot was a professional athlete, and he was the best in his field. He was a sprinter, and he was the fastest in the world. He had won countless races and had become a celebrity in the vegetable world.\n",
      "\n",
      "Everyone admired him, and he was the envy of all the other vegetables. He was the carrot that everyone wanted to be like.\n",
      "\n",
      "But then one day, tragedy struck. Jason was competing in a race, and he was in the lead. But then, out of nowhere, a rabbit appeared and raced past him. Jason was so shocked that he stopped running and watched as the rabbit crossed the finish line first.\n",
      "\n",
      "Jason was devastated. He had been so close to winning, and now he had lost. He felt like his heart had been broken. He had worked so hard to be the best, and now he had been beaten by a rabbit.\n",
      "\n",
      "He was so embarrassed that he never raced again. He stayed in his garden, feeling sorry for himself and never wanting to compete again. He had lost the one thing that had made him feel special.\n",
      "\n",
      "Jason the carrot had his heart broken, and he never recovered.\u001b[0m\n",
      "\n",
      "\u001b[1mHuggingFaceHub\u001b[0m\n",
      "Params: {'repo_id': 'google/flan-ul2', 'task': None, 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 200}}\n",
      "\u001b[38;5;200m\u001b[1;3mJason was a professional carrot. He played in the big leagues. He was a star. He was loved by all. One day he was injured. He was sent home. He was heart broken.\u001b[0m\n",
      "\n",
      "\u001b[1mHuggingFaceHub\u001b[0m\n",
      "Params: {'repo_id': 'google/flan-t5-xxl', 'task': None, 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 200}}\n",
      "\u001b[32;1m\u001b[1;3mJason was a professional athlete. He was a football player. He was very good at his job. One day, he was playing football with his team. He was very happy. Then, his team lost. Jason was very sad. He was very upset. He cried. He was very sad. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried. He cried\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "You are a creative story teller who can write wonderful interesting short stories: {question}\n",
    "\n",
    "Story:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['question'])\n",
    "\n",
    "lab = ModelLaboratory.from_llms([chatGPT_turbo,\n",
    "                                 gpt3_davinci_003,\n",
    "                                #  gpt_j6B,\n",
    "                                 flan_20B,\n",
    "                                 flan_t5xxl\n",
    "                                 ]\n",
    "                                 , prompt = prompt)\n",
    "\n",
    "lab.compare(\"\"\"\n",
    "Write a sad story about a carrot named Jason. The story should start with the carrot being a professional athlete of some kind, and end with the carrot having his heart broken.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "\n",
      "I am riding a bicycle. The pedals are moving fast. I look into the mirror and I am not moving. Why is this?\n",
      "\n",
      "\n",
      "\u001b[1mOpenAIChat\u001b[0m\n",
      "Params: {'model_name': 'gpt-3.5-turbo', 'temperature': 0.1, 'max_tokens': 256}\n",
      "\u001b[36;1m\u001b[1;3mI don't know.\u001b[0m\n",
      "\n",
      "\u001b[1mOpenAI\u001b[0m\n",
      "Params: {'model_name': 'text-davinci-003', 'temperature': 0.1, 'max_tokens': 256, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n",
      "\u001b[33;1m\u001b[1;3m You are likely coasting, meaning you are not pedaling and the bike is still moving due to the momentum from your previous pedaling.\u001b[0m\n",
      "\n",
      "\u001b[1mHuggingFaceHub\u001b[0m\n",
      "Params: {'repo_id': 'google/flan-ul2', 'task': None, 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 200}}\n",
      "\u001b[38;5;200m\u001b[1;3mI am stationary\u001b[0m\n",
      "\n",
      "\u001b[1mHuggingFaceHub\u001b[0m\n",
      "Params: {'repo_id': 'google/flan-t5-xxl', 'task': None, 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 200}}\n",
      "\u001b[32;1m\u001b[1;3mI am looking at the wrong angle.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Answer the question to the best of your abilities but if you are not sure then answer you don't know: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "lab = ModelLaboratory.from_llms([chatGPT_turbo,\n",
    "                                 gpt3_davinci_003,\n",
    "                                #  gpt_j6B,\n",
    "                                 flan_20B,\n",
    "                                 flan_t5xxl\n",
    "                                 ]\n",
    "                                 , prompt = prompt)\n",
    "\n",
    "lab.compare(\"\"\"\n",
    "I am riding a bicycle. The pedals are moving fast. I look into the mirror and I am not moving. Why is this?\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "Please answer the question:\n",
      "\n",
      "Who is the OnePlus COO?\n",
      "\n",
      "\n",
      "Output in the format: [first_name, surname]\n",
      "\n",
      "\n",
      "\n",
      "Smartphone makers searched for a way forward at MWC 2023\n",
      "Foldables, 6G, light shows -- there are a lot of ideas floating around, but no one has cracked the code\n",
      "The slowdown was inevitable, of course. Nothing stays hot forever — especially in this industry. By tech standards, smartphones have had a good run, but the last few years have seen device makers searching for the magic bullet to help the sales slide reverse course. The arrival of 5G was a nice reprieve, but next-generation telecom standards don’t arrive every year.\n",
      "\n",
      "“I personally think foldables are supply chain-driven innovation and not consumer insights,” Pei said. “Somebody invents OLED, and they can make a lot of money, because it’s a great technology. Then after a few years, a lot more companies make that, so they need to lower their prices. So they need to figure out what else they can sell at a higher margin. They develop flexible OLEDs, which they can sell at a higher price.”\n",
      "It’s hard not to be cynical about this stuff sometimes. Ditto for concept devices, though as I noted in my “ode to weird tech” post, as someone who follows this stuff for a living, I’m a fan of weirdness for weirdness sake, be it the rollable Motorola Rizr screen or the OnePlus glowing cooling fluid. Certainly following the automotive industry’s lead of creating concept devices is a trend that is likely to only become more pervasive.\n",
      "\n",
      "OnePlus COO Kinder Liu told me this week that gauging consumer interest is one of the “multiple reasons” his company is engaging with the concept. He added, “Also, we want to encourage continuous innovation inside our company.”\n",
      "\n",
      "Pretty much everyone I engaged with this week echoed the sentiment that smartphones are in a rut. For the first time, however, it’s not a foregone conclusion that there’s a way of getting out.\n",
      "\n",
      "\n",
      "\u001b[1mOpenAIChat\u001b[0m\n",
      "Params: {'model_name': 'gpt-3.5-turbo', 'temperature': 0.1, 'max_tokens': 256}\n",
      "\u001b[36;1m\u001b[1;3m[Kinder, Liu]\u001b[0m\n",
      "\n",
      "\u001b[1mOpenAI\u001b[0m\n",
      "Params: {'model_name': 'text-davinci-003', 'temperature': 0.1, 'max_tokens': 256, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n",
      "\u001b[33;1m\u001b[1;3m [Kinder, Liu]\u001b[0m\n",
      "\n",
      "\u001b[1mHuggingFaceHub\u001b[0m\n",
      "Params: {'repo_id': 'google/flan-ul2', 'task': None, 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 200}}\n",
      "\u001b[38;5;200m\u001b[1;3mKinder [surname] Liu\u001b[0m\n",
      "\n",
      "\u001b[1mHuggingFaceHub\u001b[0m\n",
      "Params: {'repo_id': 'google/flan-t5-xxl', 'task': None, 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 200}}\n",
      "\u001b[32;1m\u001b[1;3mKinder, Liu\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"{question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['question'])\n",
    "\n",
    "lab = ModelLaboratory.from_llms([chatGPT_turbo,\n",
    "                                 gpt3_davinci_003,\n",
    "                                #  gpt_j6B,\n",
    "                                 flan_20B,\n",
    "                                 flan_t5xxl\n",
    "                                 ]\n",
    "                                 , prompt = prompt)\n",
    "\n",
    "lab.compare('''Please answer the question:\\n\n",
    "Who is the OnePlus COO?\\n\\n\n",
    "Output in the format: [first_name, surname]\\n\\n\n",
    "\n",
    "Smartphone makers searched for a way forward at MWC 2023\n",
    "Foldables, 6G, light shows -- there are a lot of ideas floating around, but no one has cracked the code\n",
    "The slowdown was inevitable, of course. Nothing stays hot forever — especially in this industry. By tech standards, smartphones have had a good run, but the last few years have seen device makers searching for the magic bullet to help the sales slide reverse course. The arrival of 5G was a nice reprieve, but next-generation telecom standards don’t arrive every year.\n",
    "\n",
    "“I personally think foldables are supply chain-driven innovation and not consumer insights,” Pei said. “Somebody invents OLED, and they can make a lot of money, because it’s a great technology. Then after a few years, a lot more companies make that, so they need to lower their prices. So they need to figure out what else they can sell at a higher margin. They develop flexible OLEDs, which they can sell at a higher price.”\n",
    "It’s hard not to be cynical about this stuff sometimes. Ditto for concept devices, though as I noted in my “ode to weird tech” post, as someone who follows this stuff for a living, I’m a fan of weirdness for weirdness sake, be it the rollable Motorola Rizr screen or the OnePlus glowing cooling fluid. Certainly following the automotive industry’s lead of creating concept devices is a trend that is likely to only become more pervasive.\n",
    "\n",
    "OnePlus COO Kinder Liu told me this week that gauging consumer interest is one of the “multiple reasons” his company is engaging with the concept. He added, “Also, we want to encourage continuous innovation inside our company.”\n",
    "\n",
    "Pretty much everyone I engaged with this week echoed the sentiment that smartphones are in a rut. For the first time, however, it’s not a foregone conclusion that there’s a way of getting out.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "Please answer the question:\n",
      "\n",
      "What is a supply chain driven innovation?\n",
      "\n",
      "\n",
      "\n",
      "Smartphone makers searched for a way forward at MWC 2023\n",
      "Foldables, 6G, light shows -- there are a lot of ideas floating around, but no one has cracked the code\n",
      "The slowdown was inevitable, of course. Nothing stays hot forever — especially in this industry. By tech standards, smartphones have had a good run, but the last few years have seen device makers searching for the magic bullet to help the sales slide reverse course. The arrival of 5G was a nice reprieve, but next-generation telecom standards don’t arrive every year.\n",
      "\n",
      "“I personally think foldables are supply chain-driven innovation and not consumer insights,” Pei said. “Somebody invents OLED, and they can make a lot of money, because it’s a great technology. Then after a few years, a lot more companies make that, so they need to lower their prices. So they need to figure out what else they can sell at a higher margin. They develop flexible OLEDs, which they can sell at a higher price.”\n",
      "It’s hard not to be cynical about this stuff sometimes. Ditto for concept devices, though as I noted in my “ode to weird tech” post, as someone who follows this stuff for a living, I’m a fan of weirdness for weirdness sake, be it the rollable Motorola Rizr screen or the OnePlus glowing cooling fluid. Certainly following the automotive industry’s lead of creating concept devices is a trend that is likely to only become more pervasive.\n",
      "\n",
      "OnePlus COO Kinder Liu told me this week that gauging consumer interest is one of the “multiple reasons” his company is engaging with the concept. He added, “Also, we want to encourage continuous innovation inside our company.”\n",
      "\n",
      "Pretty much everyone I engaged with this week echoed the sentiment that smartphones are in a rut. For the first time, however, it’s not a foregone conclusion that there’s a way of getting out.\n",
      "\n",
      "\n",
      "\u001b[1mOpenAIChat\u001b[0m\n",
      "Params: {'model_name': 'gpt-3.5-turbo', 'temperature': 0.1, 'max_tokens': 256}\n",
      "\u001b[36;1m\u001b[1;3mA supply chain-driven innovation refers to an innovation or technological advancement that is primarily driven by the capabilities and advancements within the supply chain. In the context of the article, it refers to the development of flexible OLEDs for foldable smartphones as a way for companies to differentiate themselves and sell at a higher margin, due to the saturation and price competition in the market for traditional OLEDs.\u001b[0m\n",
      "\n",
      "\u001b[1mOpenAI\u001b[0m\n",
      "Params: {'model_name': 'text-davinci-003', 'temperature': 0.1, 'max_tokens': 256, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n",
      "\u001b[33;1m\u001b[1;3m Supply chain driven innovation is when companies use new technologies and materials to create products that can be sold at a higher margin. This is often done in response to market saturation and the need to find new ways to differentiate products. Examples of this include foldable OLEDs and concept devices.\u001b[0m\n",
      "\n",
      "\u001b[1mHuggingFaceHub\u001b[0m\n",
      "Params: {'repo_id': 'google/flan-ul2', 'task': None, 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 200}}\n",
      "\u001b[38;5;200m\u001b[1;3mfoldables\u001b[0m\n",
      "\n",
      "\u001b[1mHuggingFaceHub\u001b[0m\n",
      "Params: {'repo_id': 'google/flan-t5-xxl', 'task': None, 'model_kwargs': {'temperature': 0.1, 'max_new_tokens': 200}}\n",
      "\u001b[32;1m\u001b[1;3mfoldables\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lab.compare('''Please answer the question:\\n\n",
    "What is a supply chain driven innovation?\\n\\n\n",
    "\n",
    "Smartphone makers searched for a way forward at MWC 2023\n",
    "Foldables, 6G, light shows -- there are a lot of ideas floating around, but no one has cracked the code\n",
    "The slowdown was inevitable, of course. Nothing stays hot forever — especially in this industry. By tech standards, smartphones have had a good run, but the last few years have seen device makers searching for the magic bullet to help the sales slide reverse course. The arrival of 5G was a nice reprieve, but next-generation telecom standards don’t arrive every year.\n",
    "\n",
    "“I personally think foldables are supply chain-driven innovation and not consumer insights,” Pei said. “Somebody invents OLED, and they can make a lot of money, because it’s a great technology. Then after a few years, a lot more companies make that, so they need to lower their prices. So they need to figure out what else they can sell at a higher margin. They develop flexible OLEDs, which they can sell at a higher price.”\n",
    "It’s hard not to be cynical about this stuff sometimes. Ditto for concept devices, though as I noted in my “ode to weird tech” post, as someone who follows this stuff for a living, I’m a fan of weirdness for weirdness sake, be it the rollable Motorola Rizr screen or the OnePlus glowing cooling fluid. Certainly following the automotive industry’s lead of creating concept devices is a trend that is likely to only become more pervasive.\n",
    "\n",
    "OnePlus COO Kinder Liu told me this week that gauging consumer interest is one of the “multiple reasons” his company is engaging with the concept. He added, “Also, we want to encourage continuous innovation inside our company.”\n",
    "\n",
    "Pretty much everyone I engaged with this week echoed the sentiment that smartphones are in a rut. For the first time, however, it’s not a foregone conclusion that there’s a way of getting out.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
